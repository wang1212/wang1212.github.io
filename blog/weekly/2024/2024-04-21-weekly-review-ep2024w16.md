---
title: 「每周回顾」EP2024W16：算法可视化、命名规范与 MoE 架构
date: 2024-04-18 18:00:00
update: 2024-04-18 18:00:00
authors: wang1212
tags: &ref_0
  - 每周回顾
keywords: *ref_0
description: 2024 年第 16 周的回顾，算法可视化强调了通过视觉辅助理解复杂算法迭代的重要性。命名规范提供了一份实用的参考列表，旨在帮助开发者解决变量和函数命名难题。此外，文章还深入探讨了 MoE（混合专家）架构如何影响 Transformer 模型，揭示了这一在大语言模型领域日益增长的技术趋势。
---

:::note[AI 总结]

算法可视化强调了通过视觉辅助理解复杂算法迭代的重要性。命名规范提供了一份实用的参考列表，旨在帮助开发者解决变量和函数命名难题。此外，文章还深入探讨了 MoE（混合专家）架构如何影响 Transformer 模型，揭示了这一在大语言模型领域日益增长的技术趋势。

:::

<!-- truncate -->

##### [Visualizing Algorithms](https://bost.ocks.org/mike/algorithms/)

算法通常难以理解，如果能借助可视化手段辅助，将可以更好地理解算法的迭代过程。

`算法` `可视化`

##### [Naming things needn’t be hard](https://classnames.paulrobertlloyd.com/)

一篇关于命名的参考列表，对于变量、函数命名有困难的可以作为参考。

`Naming`

##### [How do mixture-of-experts layers affect transformer models?](https://stackoverflow.blog/2024/04/04/how-do-mixture-of-experts-layers-affect-transformer-models/)

MoE 架构是近期大语言模型领域技术发展的趋势，这篇文章解释了 MoE 架构是如何影响 Transformer 模型的。

`AI` `LLMs` `MoE`
